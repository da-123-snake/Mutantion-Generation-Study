[
    {
        "id": 8,
        "filepath": "/mnt/disk1/cmd/defects4j_fixed/JacksonCore/JacksonCore_11_fixed/src/main/java/com/fasterxml/jackson/core/sym/ByteQuadsCanonicalizer.java",
        "precode": "        if (_needRehash) {",
        "line": 884,
        "aftercode": ""
    },
    {
        "id": 8,
        "filepath": "/mnt/disk1/cmd/defects4j_fixed/JacksonCore/JacksonCore_11_fixed/src/main/java/com/fasterxml/jackson/core/sym/ByteQuadsCanonicalizer.java",
        "precode": "            _names = Arrays.copyOf(_names, _names.length);",
        "line": 878,
        "aftercode": "_names = Arrays.copyOf(_names);"
    },
    {
        "id": 8,
        "filepath": "/mnt/disk1/cmd/defects4j_fixed/JacksonCore/JacksonCore_11_fixed/src/main/java/com/fasterxml/jackson/core/sym/ByteQuadsCanonicalizer.java",
        "precode": "            _hashArea = Arrays.copyOf(_hashArea, _hashArea.length);",
        "line": 877,
        "aftercode": "_hashArea = Arrays.copyOf(_hashArea);"
    },
    {
        "id": 8,
        "filepath": "/mnt/disk1/cmd/defects4j_fixed/JacksonCore/JacksonCore_11_fixed/src/main/java/com/fasterxml/jackson/core/sym/ByteQuadsCanonicalizer.java",
        "precode": "            _hashArea = Arrays.copyOf(_hashArea, _hashArea.length);",
        "line": 877,
        "aftercode": "_hashArea = Arrays.copyOf();"
    },
    {
        "id": 8,
        "filepath": "/mnt/disk1/cmd/defects4j_fixed/JacksonCore/JacksonCore_11_fixed/src/main/java/com/fasterxml/jackson/core/sym/ByteQuadsCanonicalizer.java",
        "precode": "            rehash();",
        "line": 885,
        "aftercode": "rehash(false);"
    },
    {
        "id": 8,
        "filepath": "/mnt/disk1/cmd/defects4j_fixed/JacksonCore/JacksonCore_11_fixed/src/main/java/com/fasterxml/jackson/core/sym/ByteQuadsCanonicalizer.java",
        "precode": "            rehash();",
        "line": 885,
        "aftercode": "rehash(true);"
    },
    {
        "id": 8,
        "filepath": "/mnt/disk1/cmd/defects4j_fixed/JacksonCore/JacksonCore_11_fixed/src/main/java/com/fasterxml/jackson/core/sym/ByteQuadsCanonicalizer.java",
        "precode": "            _names = Arrays.copyOf(_names, _names.length);",
        "line": 878,
        "aftercode": "_names = Arrays.copyOf(_names, _names);"
    },
    {
        "id": 8,
        "filepath": "/mnt/disk1/cmd/defects4j_fixed/JacksonCore/JacksonCore_11_fixed/src/main/java/com/fasterxml/jackson/core/sym/ByteQuadsCanonicalizer.java",
        "precode": "            _hashArea = Arrays.copyOf(_hashArea, _hashArea.length);",
        "line": 877,
        "aftercode": "_hashArea = Arrays.copyOf(_names, _names.length);"
    },
    {
        "id": 8,
        "filepath": "/mnt/disk1/cmd/defects4j_fixed/JacksonCore/JacksonCore_11_fixed/src/main/java/com/fasterxml/jackson/core/sym/ByteQuadsCanonicalizer.java",
        "precode": "            _hashArea = Arrays.copyOf(_hashArea, _hashArea.length);",
        "line": 877,
        "aftercode": "_hashArea = Arrays.copyOf(_hashArea, _hashArea);"
    },
    {
        "id": 8,
        "filepath": "/mnt/disk1/cmd/defects4j_fixed/JacksonCore/JacksonCore_11_fixed/src/main/java/com/fasterxml/jackson/core/sym/ByteQuadsCanonicalizer.java",
        "precode": "        if (_needRehash) {",
        "line": 879,
        "aftercode": "package com.fasterxml.jackson.core.sym;\n\nimport java.util.Arrays;\nimport java.util.concurrent.atomic.AtomicReference;\n\nimport com.fasterxml.jackson.core.JsonFactory;\nimport com.fasterxml.jackson.core.util.InternCache;\n\n/**\n * Replacement for <code>BytesToNameCanonicalizer</code> which aims at more localized\n * memory access due to flattening of name quad data.\n * Performance improvement modest for simple JSON document data binding (maybe 3%),\n * but should help more for larger symbol tables, or for binary formats like Smile.\n *\n * @since 2.6\n */\npublic final class ByteQuadsCanonicalizer\n{\n    /**\n     * Initial size of the primary hash area. Each entry consumes 4 ints (16 bytes),\n     * and secondary area is same as primary; so default size will use 2kB of memory_tertiaryStart\n     * (plus 64x4 or 64x8 (256/512 bytes) for references to Strings, and Strings\n     * themselves).\n     */\n    private static final int DEFAULT_T_SIZE = 64;\n//    private static final int DEFAULT_T_SIZE = 256;\n\n    /**\n     * Let's not expand symbol tables past some maximum size;\n     * this should protected against OOMEs caused by large documents\n     * with unique (~= random) names.\n     * Size is in \n     */\n    private static final int MAX_T_SIZE = 0x10000; // 64k entries == 2M mem hash area\n\n    /**\n     * No point in trying to construct tiny tables, just need to resize soon.\n     */\n    final static int MIN_HASH_SIZE = 16;\n    \n    /**\n     * Let's only share reasonably sized symbol tables. Max size set to 3/4 of 8k;\n     * this corresponds to 256k main hash index. This should allow for enough distinct\n     * names for almost any case, while preventing ballooning for cases where names\n     * are unique (or close thereof).\n     */\n    final static int MAX_ENTRIES_FOR_REUSE = 6000;\n\n    /*\n    /**********************************************************\n    /* Linkage, needed for merging symbol tables\n    /**********************************************************\n     */\n\n    /**\n     * Reference to the root symbol table, for child tables, so\n     * that they can merge table information back as necessary.\n     */\n    final protected ByteQuadsCanonicalizer _parent;\n\n    /**\n     * Member that is only used by the root table instance: root\n     * passes immutable state into child instances, and children\n     * may return new state if they add entries to the table.\n     * Child tables do NOT use the reference.\n     */\n    final protected AtomicReference<TableInfo> _tableInfo;\n    \n    /**\n     * Seed value we use as the base to make hash codes non-static between\n     * different runs, but still stable for lifetime of a single symbol table\n     * instance.\n     * This is done for security reasons, to avoid potential DoS attack via\n     * hash collisions.\n     */\n    final private int _seed;\n    \n    /*\n    /**********************************************************\n    /* Configuration\n    /**********************************************************\n     */\n\n    /**\n     * Whether canonical symbol Strings are to be intern()ed before added\n     * to the table or not.\n     *<p>\n     * NOTE: non-final to allow disabling intern()ing in case of excessive\n     * collisions.\n     */\n    protected boolean _intern;\n\n    /**\n     * Flag that indicates whether we should throw an exception if enough \n     * hash collisions are detected (true); or just worked around (false).\n     * \n     * @since 2.4\n     */\n    protected final boolean _failOnDoS;\n    \n    /*\n    /**********************************************************\n    /* First, main hash area info\n    /**********************************************************\n     */\n\n    /**\n     * Primary hash information area: consists of <code>2 * _hashSize</code>\n     * entries of 16 bytes (4 ints), arranged in a cascading lookup\n     * structure (details of which may be tweaked depending on expected rates\n     * of collisions).\n     */\n    protected int[] _hashArea;\n\n    /**\n     * Number of slots for primary entries within {@link #_hashArea}; which is\n     * at most <code>1/8</code> of actual size of the underlying array (4-int slots,\n     * primary covers only half of the area; plus, additional area for longer\n     * symbols after hash area).\n     */\n    protected int _hashSize;\n\n    /**\n     * Offset within {@link #_hashArea} where secondary entries start\n     */\n    protected int _secondaryStart;\n\n    /**\n     * Offset within {@link #_hashArea} where tertiary entries start\n     */\n    protected int _tertiaryStart;\n    \n    /**\n     * Constant that determines size of buckets for tertiary entries:\n     * <code>1 &lt;&lt; _tertiaryShift</code> is the size, and shift value\n     * is also used for translating from primary offset into\n     * tertiary bucket (shift right by <code>4 + _tertiaryShift</code>).\n     *<p>\n     * Default value is 2, for buckets of 4 slots; grows bigger with\n     * bigger table sizes.\n     */\n    protected int _tertiaryShift;\n\n    /**\n     * Total number of Strings in the symbol table; only used for child tables.\n     */\n    protected int _count;\n\n    /**\n     * Array that contains <code>String</code> instances matching\n     * entries in {@link #_hashArea}.\n     * Contains nulls for unused entries. Note that this size is twice\n     * that of {@link #_hashArea}\n     */\n    protected String[] _names;\n\n    /*\n    /**********************************************************\n    /* Then information on collisions etc\n    /**********************************************************\n     */\n\n    /**\n     * Pointer to the offset within spill-over area where there is room\n     * for more spilled over entries (if any).\n     * Spill over area is within fixed-size portion of {@link #_hashArea}.\n     */\n    protected int _spilloverEnd;\n\n    /**\n     * Offset within {@link #_hashArea} that follows main slots and contains\n     * quads for longer names (13 bytes or longers), and points to the\n     * first available int that may be used for appending quads of the next\n     * long name.\n     * Note that long name area follows immediately after the fixed-size\n     * main hash area ({@link #_hashArea}).\n     */\n    protected int _longNameOffset;\n\n    /**\n     * This flag is set if, after adding a new entry, it is deemed\n     * that a rehash is warranted if any more entries are to be added.\n     */\n    private transient boolean _needRehash;\n\n    /*\n    /**********************************************************\n    /* Sharing, versioning\n    /**********************************************************\n     */\n\n    // // // Which of the buffers may be shared (and are copy-on-write)?\n\n    /**\n     * Flag that indicates whether underlying data structures for\n     * the main hash area are shared or not. If they are, then they\n     * need to be handled in copy-on-write way, i.e. if they need\n     * to be modified, a copy needs to be made first; at this point\n     * it will not be shared any more, and can be modified.\n     *<p>\n     * This flag needs to be checked both when adding new main entries,\n     * and when adding new collision list queues (i.e. creating a new\n     * collision list head entry)\n     */\n    private boolean _hashShared;\n\n    /*\n    /**********************************************************\n    /* Life-cycle: constructors\n    /**********************************************************\n     */\n\n    /**\n     * Constructor used for creating per-<code>JsonFactory</code> \"root\"\n     * symbol tables: ones used for merging and sharing common symbols\n     * \n     * @param sz Initial primary hash area size\n     * @param intern Whether Strings contained should be {@link String#intern}ed\n     * @param seed Random seed valued used to make it more difficult to cause\n     *   collisions (used for collision-based DoS attacks).\n     */\n    private ByteQuadsCanonicalizer(int sz, boolean intern, int seed, boolean failOnDoS) {\n        _parent = null;\n        _seed = seed;\n        _intern = intern;\n        _failOnDoS = failOnDoS;\n        // Sanity check: let's now allow hash sizes below certain minimum value\n        if (sz < MIN_HASH_SIZE) {\n            sz = MIN_HASH_SIZE;\n        } else {\n            // Also; size must be 2^N; otherwise hash algorithm won't\n            // work... so let's just pad it up, if so\n            if ((sz & (sz - 1)) != 0) { // only true if it's 2^N\n                int curr = MIN_HASH_SIZE;\n                while (curr < sz) {\n                    curr += curr;\n                }\n                sz = curr;\n            }\n        }\n        _tableInfo = new AtomicReference<TableInfo>(TableInfo.createInitial(sz));\n    }\n\n    /**\n     * Constructor used when creating a child instance\n     */\n    private ByteQuadsCanonicalizer(ByteQuadsCanonicalizer parent, boolean intern,\n            int seed, boolean failOnDoS, TableInfo state)\n    {\n        _parent = parent;\n        _seed = seed;\n        _intern = intern;\n        _failOnDoS = failOnDoS;\n        _tableInfo = null; // not used by child tables\n\n        // Then copy shared state\n        _count = state.count;\n        _hashSize = state.size;\n        _secondaryStart = _hashSize << 2; // right after primary area\n        _tertiaryStart = _secondaryStart + (_secondaryStart >> 1); // right after secondary\n        _tertiaryShift = state.tertiaryShift;\n        \n        _hashArea = state.mainHash;\n        _names = state.names;\n\n        _spilloverEnd = state.spilloverEnd;\n        _longNameOffset = state.longNameOffset;\n\n        // and then set other state to reflect sharing status\n        _needRehash = false;\n        _hashShared = true;\n    }\n\n    /*\n    /**********************************************************\n    /* Life-cycle: factory methods, merging\n    /**********************************************************\n     */\n    \n    /**\n     * Factory method to call to create a symbol table instance with a\n     * randomized seed value.\n     */\n    public static ByteQuadsCanonicalizer createRoot() {\n        /* [Issue-21]: Need to use a variable seed, to thwart hash-collision\n         * based attacks.\n         */\n        long now = System.currentTimeMillis();\n        // ensure it's not 0; and might as well require to be odd so:\n        int seed = (((int) now) + ((int) (now >>> 32))) | 1;\n        return createRoot(seed);\n    }\n\n    /**\n     * Factory method that should only be called from unit tests, where seed\n     * value should remain the same.\n     */\n    protected static ByteQuadsCanonicalizer createRoot(int seed) {\n        return new ByteQuadsCanonicalizer(DEFAULT_T_SIZE, true, seed, true);\n    }\n    \n    /**\n     * Factory method used to create actual symbol table instance to\n     * use for parsing.\n     */\n    public ByteQuadsCanonicalizer makeChild(int flags) {\n        return new ByteQuadsCanonicalizer(this,\n                JsonFactory.Feature.INTERN_FIELD_NAMES.enabledIn(flags),\n                _seed,\n                JsonFactory.Feature.FAIL_ON_SYMBOL_HASH_OVERFLOW.enabledIn(flags),\n                _tableInfo.get());\n    }\n\n    /**\n     * Method called by the using code to indicate it is done\n     * with this instance. This lets instance merge accumulated\n     * changes into parent (if need be), safely and efficiently,\n     * and without calling code having to know about parent\n     * information\n     */\n    public void release()\n    {\n        // we will try to merge if child table has new entries\n        if (_parent != null && maybeDirty()) {\n            _parent.mergeChild(new TableInfo(this));\n            /* Let's also mark this instance as dirty, so that just in\n             * case release was too early, there's no corruption of possibly shared data.\n             */\n            _hashShared = true;\n        }\n    }\n\n    private void mergeChild(TableInfo childState)\n    {\n        final int childCount = childState.count;\n        TableInfo currState = _tableInfo.get();\n\n        // Should usually grow; but occasionally could also shrink if (but only if)\n        // collision list overflow ends up clearing some collision lists.\n        if (childCount == currState.count) {\n            return;\n        }\n\n        // One caveat: let's try to avoid problems with degenerate cases of documents with\n        // generated \"random\" names: for these, symbol tables would bloat indefinitely.\n        // One way to do this is to just purge tables if they grow\n        // too large, and that's what we'll do here.\n        if (childCount > MAX_ENTRIES_FOR_REUSE) {\n            // At any rate, need to clean up the tables\n            childState = TableInfo.createInitial(DEFAULT_T_SIZE);\n        }\n        _tableInfo.compareAndSet(currState, childState);\n    }\n\n    /*\n    /**********************************************************\n    /* API, accessors\n    /**********************************************************\n     */\n\n    public int size()\n    {\n        if (_tableInfo != null) { // root table\n            return _tableInfo.get().count;\n        }\n        // nope, child table\n        return _count;\n    }\n\n    /**\n     * Returns number of primary slots table has currently\n     */\n    public int bucketCount() { return _hashSize; }\n\n    /**\n     * Method called to check to quickly see if a child symbol table\n     * may have gotten additional entries. Used for checking to see\n     * if a child table should be merged into shared table.\n     */\n    public boolean maybeDirty() { return !_hashShared; }\n\n    public int hashSeed() { return _seed; }\n    \n    /**\n     * Method mostly needed by unit tests; calculates number of\n     * entries that are in the primary slot set. These are\n     * \"perfect\" entries, accessible with a single lookup\n     */\n    public int primaryCount()\n    {\n        int count = 0;\n        for (int offset = 3, end = _secondaryStart; offset < end; offset += 4) {\n            if (_hashArea[offset] != 0) {\n                ++count;\n            }\n        }\n        return count;\n    }\n\n    /**\n     * Method mostly needed by unit tests; calculates number of entries\n     * in secondary buckets\n     */\n    public int secondaryCount() {\n        int count = 0;\n        int offset = _secondaryStart + 3;\n        for (int end = _tertiaryStart; offset < end; offset += 4) {\n            if (_hashArea[offset] != 0) {\n                ++count;\n            }\n        }\n        return count;\n    }\n\n    /**\n     * Method mostly needed by unit tests; calculates number of entries\n     * in tertiary buckets\n     */\n    public int tertiaryCount() {\n        int count = 0;\n        int offset = _tertiaryStart + 3; // to 1.5x, starting point of tertiary\n        for (int end = offset + _hashSize; offset < end; offset += 4) {\n            if (_hashArea[offset] != 0) {\n                ++count;\n            }\n        }\n        return count;\n    }\n\n    /**\n     * Method mostly needed by unit tests; calculates number of entries\n     * in shared spillover area\n     */\n    public int spilloverCount() {\n        // difference between spillover end, start, divided by 4 (four ints per slot)\n        return (_spilloverEnd - _spilloverStart()) >> 2;\n    }\n\n    public int totalCount()\n    {\n        int count = 0;\n        for (int offset = 3, end = (_hashSize << 3); offset < end; offset += 4) {\n            if (_hashArea[offset] != 0) {\n                ++count;\n            }\n        }\n        return count;\n    }\n\n    @Override\n    public String toString() {\n        int pri = primaryCount();\n        int sec = secondaryCount();\n        int tert = tertiaryCount();\n        int spill = spilloverCount();\n        int total = totalCount();\n        return String.format(\"[%s: size=%d, hashSize=%d, %d/%d/%d/%d pri/sec/ter/spill (=%s), total:%d]\",\n                getClass().getName(), _count, _hashSize,\n                pri, sec, tert, spill, total, (pri+sec+tert+spill), total);\n    }\n\n    /*\n    /**********************************************************\n    /* Public API, accessing symbols\n    /**********************************************************\n     */\n\n    public String findName(int q1)\n    {\n        int offset = _calcOffset(calcHash(q1));\n        // first: primary match?\n        final int[] hashArea = _hashArea;\n\n        int len = hashArea[offset+3];\n\n        if (len == 1) {\n            if (hashArea[offset] == q1) {\n                return _names[offset >> 2];\n            }\n        } else if (len == 0) { // empty slot; unlikely but avoid further lookups if so\n            return null;\n        }\n        // secondary? single slot shared by N/2 primaries\n        int offset2 = _secondaryStart + ((offset >> 3) << 2);\n\n        len = hashArea[offset2+3];\n\n        if (len == 1) {\n            if (hashArea[offset2] == q1) {\n                return _names[offset2 >> 2];\n            }\n        } else if (len == 0) { // empty slot; unlikely but avoid further lookups if so\n            return null;\n        }\n\n        // tertiary lookup & spillovers best to offline\n        return _findSecondary(offset, q1);\n    }\n\n    public String findName(int q1, int q2)\n    {\n        int offset = _calcOffset(calcHash(q1, q2));\n\n        final int[] hashArea = _hashArea;\n\n        int len = hashArea[offset+3];\n\n        if (len == 2) {\n            if ((q1 == hashArea[offset]) && (q2 == hashArea[offset+1])) {\n                return _names[offset >> 2];\n            }\n        } else if (len == 0) { // empty slot; unlikely but avoid further lookups if so\n            return null;\n        }\n        // secondary?\n        int offset2 = _secondaryStart + ((offset >> 3) << 2);\n\n        len = hashArea[offset2+3];\n\n        if (len == 2) {\n            if ((q1 == hashArea[offset2]) && (q2 == hashArea[offset2+1])) {\n                return _names[offset2 >> 2];\n            }\n        } else if (len == 0) { // empty slot? Short-circuit if no more spillovers\n            return null;\n        }\n        return _findSecondary(offset, q1, q2);\n    }\n\n    public String findName(int q1, int q2, int q3)\n    {\n        int offset = _calcOffset(calcHash(q1, q2, q3));\n        final int[] hashArea = _hashArea;\n        int len = hashArea[offset+3];\n\n        if (len == 3) {\n            if ((q1 == hashArea[offset]) && (hashArea[offset+1] == q2) && (hashArea[offset+2] == q3)) {\n                return _names[offset >> 2];\n            }\n        } else if (len == 0) { // empty slot; unlikely but avoid further lookups if so\n            return null;\n        }\n        // secondary?\n        int offset2 = _secondaryStart + ((offset >> 3) << 2);\n\n        len = hashArea[offset2+3];\n\n        if (len == 3) {\n            if ((q1 == hashArea[offset2]) && (hashArea[offset2+1] == q2) && (hashArea[offset2+2] == q3)) {\n                return _names[offset2 >> 2];\n            }\n        } else if (len == 0) { // empty slot? Short-circuit if no more spillovers\n            return null;\n        }\n        return _findSecondary(offset, q1, q2, q3);\n    }\n\n    public String findName(int[] q, int qlen)\n    {\n        /* This version differs significantly, because longer names do not fit within cell.\n         * Rather, they contain hash in main slot, and offset+length to extension area\n         * that contains actual quads.\n         */\n        if (qlen < 4) { // another sanity check\n            if (qlen == 3) {\n                return findName(q[0], q[1], q[2]);\n            }\n            if (qlen == 2) {\n                return findName(q[0], q[1]);\n            }\n            return findName(q[0]);\n        }\n        final int hash = calcHash(q, qlen);\n        int offset = _calcOffset(hash);\n\n        final int[] hashArea = _hashArea;\n\n        final int len = hashArea[offset+3];\n        \n        if ((hash == hashArea[offset]) && (len == qlen)) {\n            // probable but not guaranteed: verify\n            if (_verifyLongName(q, qlen, hashArea[offset+1])) {\n                return _names[offset >> 2];\n            }\n        }\n        if (len == 0) { // empty slot; unlikely but avoid further lookups if so\n            return null;\n        }\n        // secondary?\n        int offset2 = _secondaryStart + ((offset >> 3) << 2);\n\n        final int len2 = hashArea[offset2+3];\n        if ((hash == hashArea[offset2]) && (len2 == qlen)) {\n            if (_verifyLongName(q, qlen, hashArea[offset2+1])) {\n                return _names[offset2 >> 2];\n            }\n        }\n        if (len == 0) { // empty slot? Short-circuit if no more spillovers\n            return null;\n        }\n        return _findSecondary(offset, hash, q, qlen);\n    }\n    \n    private final int _calcOffset(int hash)\n    {\n        // NOTE: simple for initial impl, but we may want to interleave it a bit\n        // in near future\n        // So: first, hash into primary hash index\n        int ix = hash & (_hashSize-1);\n        // keeping in mind we have 4 ints per entry\n        return (ix << 2);\n    }\n\n    /*\n    /**********************************************************\n    /* Access from spill-over areas\n    /**********************************************************\n     */\n\n    private String _findSecondary(int origOffset, int q1)\n    {\n        // tertiary area division is dynamic. First; its size is N/4 compared to\n        // primary hash size; and offsets are for 4 int slots. So to get to logical\n        // index would shift by 4. But! Tertiary area is further split into buckets,\n        // determined by shift value. And finally, from bucket back into physical offsets\n        int offset = _tertiaryStart + ((origOffset >> (_tertiaryShift + 2)) << _tertiaryShift);\n        final int[] hashArea = _hashArea;\n        final int bucketSize = (1 << _tertiaryShift);\n        for (int end = offset + bucketSize; offset < end; offset += 4) {\n            int len = hashArea[offset+3];\n            if ((q1 == hashArea[offset]) && (1 == len)) {\n                return _names[offset >> 2];\n            }\n            if (len == 0) {\n                return null;\n            }\n        }\n        // but if tertiary full, check out spill-over area as last resort\n        // shared spillover starts at 7/8 of the main hash area\n        // (which is sized at 2 * _hashSize), so:\n        for (offset = _spilloverStart(); offset < _spilloverEnd; offset += 4) {\n            if ((q1 == hashArea[offset]) && (1 == hashArea[offset+3])) {\n                return _names[offset >> 2];\n            }\n        }\n        return null;\n    }\n\n    private String _findSecondary(int origOffset, int q1, int q2)\n    {\n        int offset = _tertiaryStart + ((origOffset >> (_tertiaryShift + 2)) << _tertiaryShift);\n        final int[] hashArea = _hashArea;\n\n        final int bucketSize = (1 << _tertiaryShift);\n        for (int end = offset + bucketSize; offset < end; offset += 4) {\n            int len = hashArea[offset+3];\n            if ((q1 == hashArea[offset]) && (q2 == hashArea[offset+1]) && (2 == len)) {\n                return _names[offset >> 2];\n            }\n            if (len == 0) {\n                return null;\n            }\n        }\n        for (offset = _spilloverStart(); offset < _spilloverEnd; offset += 4) {\n            if ((q1 == hashArea[offset]) && (q2 == hashArea[offset+1]) && (2 == hashArea[offset+3])) {\n                return _names[offset >> 2];\n            }\n        }\n        return null;\n    }\n\n    private String _findSecondary(int origOffset, int q1, int q2, int q3)\n    {\n        int offset = _tertiaryStart + ((origOffset >> (_tertiaryShift + 2)) << _tertiaryShift);\n        final int[] hashArea = _hashArea;\n\n        final int bucketSize = (1 << _tertiaryShift);\n        for (int end = offset + bucketSize; offset < end; offset += 4) {\n            int len = hashArea[offset+3];\n            if ((q1 == hashArea[offset]) && (q2 == hashArea[offset+1]) && (q3 == hashArea[offset+2]) && (3 == len)) {\n                return _names[offset >> 2];\n            }\n            if (len == 0) {\n                return null;\n            }\n        }\n        for (offset = _spilloverStart(); offset < _spilloverEnd; offset += 4) {\n            if ((q1 == hashArea[offset]) && (q2 == hashArea[offset+1]) && (q3 == hashArea[offset+2])\n                    && (3 == hashArea[offset+3])) {\n                return _names[offset >> 2];\n            }\n        }\n        return null;\n    }\n\n    private String _findSecondary(int origOffset, int hash, int[] q, int qlen)\n    {\n        int offset = _tertiaryStart + ((origOffset >> (_tertiaryShift + 2)) << _tertiaryShift);\n        final int[] hashArea = _hashArea;\n\n        final int bucketSize = (1 << _tertiaryShift);\n        for (int end = offset + bucketSize; offset < end; offset += 4) {\n            int len = hashArea[offset+3];\n            if ((hash == hashArea[offset]) && (qlen == len)) {\n                if (_verifyLongName(q, qlen, hashArea[offset+1])) {\n                    return _names[offset >> 2];\n                }\n            }\n            if (len == 0) {\n                return null;\n            }\n        }\n        for (offset = _spilloverStart(); offset < _spilloverEnd; offset += 4) {\n            if ((hash == hashArea[offset]) && (qlen == hashArea[offset+3])) {\n                if (_verifyLongName(q, qlen, hashArea[offset+1])) {\n                    return _names[offset >> 2];\n                }\n            }\n        }\n        return null;\n    }\n    \n    private boolean _verifyLongName(int[] q, int qlen, int spillOffset)\n    {\n        final int[] hashArea = _hashArea;\n        // spillOffset assumed to be physical index right into quad string\n        int ix = 0;\n\n        switch (qlen) {\n        default:\n            return _verifyLongName2(q, qlen, spillOffset);\n        case 8:\n            if (q[ix++] != hashArea[spillOffset++]) return false;\n        case 7:\n            if (q[ix++] != hashArea[spillOffset++]) return false;\n        case 6:\n            if (q[ix++] != hashArea[spillOffset++]) return false;\n        case 5:\n            if (q[ix++] != hashArea[spillOffset++]) return false;\n        case 4: // always at least 4\n            if (q[ix++] != hashArea[spillOffset++]) return false;\n            if (q[ix++] != hashArea[spillOffset++]) return false;\n            if (q[ix++] != hashArea[spillOffset++]) return false;\n            if (q[ix++] != hashArea[spillOffset++]) return false;\n        }\n        return true;\n    }\n\n    private boolean _verifyLongName2(int[] q, int qlen, int spillOffset)\n    {\n        int ix = 0;\n        do {\n            if (q[ix++] != _hashArea[spillOffset++]) {\n                return false;\n            }\n        } while (ix < qlen);\n        return true;\n    }\n\n    /*\n    /**********************************************************\n    /* API, mutators\n    /**********************************************************\n     */\n\n    public String addName(String name, int q1) {\n        _verifySharing();\n        if (_intern) {\n            name = InternCache.instance.intern(name);\n        }\n        int offset = _findOffsetForAdd(calcHash(q1));\n        _hashArea[offset] = q1;\n        _hashArea[offset+3] = 1;\n        _names[offset >> 2] = name;\n        ++_count;\n        _verifyNeedForRehash();\n        return name;\n    }\n\n    public String addName(String name, int q1, int q2) {\n        _verifySharing();\n        if (_intern) {\n            name = InternCache.instance.intern(name);\n        }\n        int hash = (q2 == 0) ? calcHash(q1) : calcHash(q1, q2);\n        int offset = _findOffsetForAdd(hash);\n        _hashArea[offset] = q1;\n        _hashArea[offset+1] = q2;\n        _hashArea[offset+3] = 2;\n        _names[offset >> 2] = name;\n        ++_count;\n        _verifyNeedForRehash();\n        return name;\n    }\n\n    public String addName(String name, int q1, int q2, int q3) {\n        _verifySharing();\n        if (_intern) {\n            name = InternCache.instance.intern(name);\n        }\n        int offset = _findOffsetForAdd(calcHash(q1, q2, q3));\n        _hashArea[offset] = q1;\n        _hashArea[offset+1] = q2;\n        _hashArea[offset+2] = q3;\n        _hashArea[offset+3] = 3;\n        _names[offset >> 2] = name;\n        ++_count;\n        _verifyNeedForRehash();\n        return name;\n    }\n\n    public String addName(String name, int[] q, int qlen)\n    {\n        _verifySharing();\n        if (_intern) {\n            name = InternCache.instance.intern(name);\n        }\n        int offset;\n        \n        switch (qlen) {\n        case 1:\n        {\n                offset = _findOffsetForAdd(calcHash(q[0]));\n                _hashArea[offset] = q[0];\n                _hashArea[offset+3] = 1;\n            }\n            break;\n        case 2:\n            {\n                offset = _findOffsetForAdd(calcHash(q[0], q[1]));\n                _hashArea[offset] = q[0];\n                _hashArea[offset+1] = q[1];\n                _hashArea[offset+3] = 2;\n            }\n            break;\n        case 3:\n            {\n                offset = _findOffsetForAdd(calcHash(q[0], q[1], q[2]));\n                _hashArea[offset] = q[0];\n                _hashArea[offset+1] = q[1];\n                _hashArea[offset+2] = q[2];\n                _hashArea[offset+3] = 3;\n            }\n            break;\n        default:\n            final int hash = calcHash(q, qlen);\n            offset = _findOffsetForAdd(hash);\n\n            _hashArea[offset] = hash;\n            int longStart = _appendLongName(q, qlen);\n            _hashArea[offset+1] = longStart;\n            _hashArea[offset+3] = qlen;\n        }\n        // plus add the actual String\n        _names[offset >> 2] = name;\n\n        // and finally; see if we really should rehash.\n        ++_count;\n        _verifyNeedForRehash();\n        return name;\n    }\n\n    private void _verifyNeedForRehash() {\n        // Yes if above 80%, or above 50% AND have ~1% spill-overs\n        if (_count > (_hashSize >> 1)) { // over 50%\n            int spillCount = (_spilloverEnd - _spilloverStart()) >> 2;\n            if ((spillCount > (1 + _count >> 7))\n                    || (_count > (_hashSize * 0.80))) {\n                _needRehash = true;\n            }\n        }\n    }\n\n    private void _verifySharing()\n    {\n        if (_hashShared) {\n            _hashArea = Arrays.copyOf(_hashArea, _hashArea.length);\n            _names = Arrays.copyOf(_names, _names.length);\n            _hashShared = false;\n            // 09-Sep-2015, tatu: As per [jackson-core#216], also need to ensure\n            //    we rehash as needed, as need-rehash flag is not copied from parent\n            _verifyNeedForRehash();\n        }\n_verifyNeedForRehash();\n        if (_needRehash) {            rehash();\n        }\n}\n    }\n\n    /**\n     * Method called to find the location within hash table to add a new symbol in.\n     */\n    private int _findOffsetForAdd(int hash)\n    {\n        // first, check the primary:\n        int offset = _calcOffset(hash);\n        final int[] hashArea = _hashArea;\n        if (hashArea[offset+3] == 0) {\n//System.err.printf(\" PRImary slot #%d, hash %X\\n\", (offset>>2), hash & 0x7F);\n            return offset;\n        }\n        // then secondary\n        int offset2 = _secondaryStart + ((offset >> 3) << 2);\n        if (hashArea[offset2+3] == 0) {\n//System.err.printf(\" SECondary slot #%d (start x%X), hash %X\\n\",(offset >> 3), _secondaryStart, (hash & 0x7F));\n            return offset2;\n        }\n        // if not, tertiary?\n\n        offset2 = _tertiaryStart + ((offset >> (_tertiaryShift + 2)) << _tertiaryShift);\n        final int bucketSize = (1 << _tertiaryShift);\n        for (int end = offset2 + bucketSize; offset2 < end; offset2 += 4) {\n            if (hashArea[offset2+3] == 0) {\n//System.err.printf(\" TERtiary slot x%X (from x%X, start x%X), hash %X.\\n\", offset2, ((offset >> (_tertiaryShift + 2)) << _tertiaryShift), _tertiaryStart, (hash & 0x7F));\n                return offset2;\n            }\n        }\n\n        // and if even tertiary full, append at the end of spill area\n        offset = _spilloverEnd;\n        _spilloverEnd += 4;\n\n//System.err.printf(\" SPIll-over at x%X; start x%X; end x%X, hash %X\\n\", offset, _spilloverStart(), _hashArea.length, (hash & 0x7F));\n        \n        // one caveat: in the unlikely event if spill-over filling up,\n        // check if that could be considered a DoS attack; handle appropriately\n        // (NOTE: approximate for now; we could verify details if that becomes necessary)\n        /* 31-Jul-2015, tatu: Note that spillover area does NOT end at end of array,\n         *   since \"long names\" area follows. Instead, need to calculate from hash size.\n         */\n        final int end = (_hashSize << 3);\n        if (_spilloverEnd >= end) {\n            if (_failOnDoS) {\n                _reportTooManyCollisions();\n            }\n            // and if we didn't fail, we'll simply force rehash for next add\n            // (which, in turn, may double up or nuke contents, depending on size etc)\n            _needRehash = true;\n        }\n        return offset;\n    }\n\n    private int _appendLongName(int[] quads, int qlen)\n    {\n        int start = _longNameOffset;\n        \n        // note: at this point we must already be shared. But may not have enough space\n        if ((start + qlen) > _hashArea.length) {\n            // try to increment in reasonable chunks; at least space that we need\n            int toAdd = (start + qlen) - _hashArea.length;\n            // but at least 1/8 of regular hash area size or 16kB (whichever smaller)\n            int minAdd = Math.min(4096, _hashSize);\n\n            int newSize = _hashArea.length + Math.max(toAdd, minAdd);\n            _hashArea = Arrays.copyOf(_hashArea, newSize);\n        }\n        System.arraycopy(quads, 0, _hashArea, start, qlen);\n        _longNameOffset += qlen;\n        return start;\n    }\n\n    /*\n    /**********************************************************\n    /* Hash calculation\n    /**********************************************************\n     */\n\n    /* Note on hash calculation: we try to make it more difficult to\n     * generate collisions automatically; part of this is to avoid\n     * simple \"multiply-add\" algorithm (like JDK String.hashCode()),\n     * and add bit of shifting. And other part is to make this\n     * non-linear, at least for shorter symbols.\n     */\n    \n    // JDK uses 31; other fine choices are 33 and 65599, let's use 33\n    // as it seems to give fewest collisions for us\n    // (see [http://www.cse.yorku.ca/~oz/hash.html] for details)\n    private final static int MULT = 33;\n    private final static int MULT2 = 65599;\n    private final static int MULT3 = 31;\n    \n    public int calcHash(int q1)\n    {\n        int hash = q1 ^ _seed;\n        /* 29-Mar-2015, tatu: Earlier used 15 + 9 right shifts, which worked ok\n         *    except for one specific problem case: numbers. So needed to make sure\n         *    that all 4 least-significant bits participate in hash. Couple of ways\n         *    to work it out, but this is the simplest, fast and seems to do ok.\n         */\n        hash += (hash >>> 16); // to xor hi- and low- 16-bits\n        hash ^= (hash << 3); // shuffle back a bit\n        hash += (hash >>> 12); // and bit more\n        return hash;\n    }\n\n    public int calcHash(int q1, int q2)\n    {\n        // For two quads, let's change algorithm a bit, to spice\n        // things up (can do bit more processing anyway)\n        int hash = q1;\n\n        hash += (hash >>> 15); // try mixing first and second byte pairs first\n        hash ^= (hash >>> 9); // as well as lowest 2 bytes\n        hash += (q2 * MULT); // then add second quad\n        hash ^= _seed;\n        hash += (hash >>> 16); // and shuffle some more\n        hash ^= (hash >>> 4);\n        hash += (hash << 3);\n        \n        return hash;\n    }\n\n    public int calcHash(int q1, int q2, int q3)\n    { // use same algorithm as multi-byte, tested to work well\n        int hash = q1 ^ _seed;\n        hash += (hash >>> 9);\n        hash *= MULT3;\n        hash += q2;\n        hash *= MULT;\n        hash += (hash >>> 15);\n        hash ^= q3;\n        // 26-Mar-2015, tatu: As per two-quad case, a short shift seems to help more here\n        hash += (hash >>> 4);\n\n        hash += (hash >>> 15);\n        hash ^= (hash << 9);\n\n        return hash;\n    }\n\n    public int calcHash(int[] q, int qlen)\n    {\n        if (qlen < 4) {\n            throw new IllegalArgumentException();\n        }\n        /* And then change handling again for \"multi-quad\" case; mostly\n         * to make calculation of collisions less fun. For example,\n         * add seed bit later in the game, and switch plus/xor around,\n         * use different shift lengths.\n         */\n        int hash = q[0] ^ _seed;\n        hash += (hash >>> 9);\n        hash += q[1];\n        hash += (hash >>> 15);\n        hash *= MULT;\n        hash ^= q[2];\n        hash += (hash >>> 4);\n\n        for (int i = 3; i < qlen; ++i) {\n            int next = q[i];\n            next = next ^ (next >> 21);\n            hash += next;\n        }\n        hash *= MULT2;\n        \n        // and finally shuffle some more once done\n        hash += (hash >>> 19);\n        hash ^= (hash << 5);\n        return hash;\n    }\n\n    /*\n    /**********************************************************\n    /* Rehashing\n    /**********************************************************\n     */\n\n    private void rehash()\n    {\n        _needRehash = false;\n        // Note: since we'll make copies, no need to unshare, can just mark as such:\n        _hashShared = false;\n\n        // And then we can first deal with the main hash area. Since we are expanding\n        // linearly (double up), we know there'll be no collisions during this phase.\n        final int[] oldHashArea = _hashArea;\n        final String[] oldNames = _names;\n        final int oldSize = _hashSize;\n        final int oldCount = _count;\n        final int newSize = oldSize + oldSize;\n        final int oldEnd = _spilloverEnd;\n\n        /* 13-Mar-2010, tatu: Let's guard against OOME that could be caused by\n         *    large documents with unique (or mostly so) names\n         */\n        if (newSize > MAX_T_SIZE) {\n            nukeSymbols(true);\n            return;\n        }\n        // double up main hash area, but do not expand long-name area:\n        _hashArea = new int[oldHashArea.length + (oldSize<<3)];\n        _hashSize = newSize;\n        _secondaryStart = (newSize << 2); // 4 ints per entry\n        _tertiaryStart = _secondaryStart + (_secondaryStart >> 1); // right after secondary\n        _tertiaryShift = _calcTertiaryShift(newSize);\n        \n        // and simply double up name array\n        _names = new String[oldNames.length << 1];\n        nukeSymbols(false);\n\n        // Plus we can scan only through the primary hash area, looking for non-empty\n        // slots, without worrying about ordering. This should never reduce priority\n        // of existing entries: primaries remain primaries; however, due to increased\n        // space, secondaries may become primaries etc\n\n        int copyCount = 0;\n        int[] q = new int[16];\n        for (int offset = 0, end = oldEnd; offset < end; offset += 4) {\n            int len = oldHashArea[offset+3];\n            if (len == 0) { // empty slot, skip\n                continue;\n            }\n            ++copyCount;\n            String name = oldNames[offset>>2];\n            switch (len) {\n            case 1:\n                q[0] = oldHashArea[offset];\n                addName(name, q, 1);\n                break;\n            case 2:\n                q[0] = oldHashArea[offset];\n                q[1] = oldHashArea[offset+1];\n                addName(name, q, 2);\n                break;\n            case 3:\n                q[0] = oldHashArea[offset];\n                q[1] = oldHashArea[offset+1];\n                q[2] = oldHashArea[offset+2];\n                addName(name, q, 3);\n                break;\n            default:\n                if (len > q.length) {\n                    q = new int[len];\n                }\n                // #0 is hash, #1 offset\n                int qoff = oldHashArea[offset+1];\n                System.arraycopy(oldHashArea, qoff, q, 0, len);\n                addName(name, q, len);\n                break;\n            }\n        }\n\n        // Sanity checks: since corruption difficult to detect, assert explicitly\n        // with production code\n        if (copyCount != oldCount) {\n            throw new IllegalStateException(\"Failed rehash(): old count=\"+oldCount+\", copyCount=\"+copyCount);\n        }\n    }\n\n    /**\n     * Helper method called to empty all shared symbols, but to leave\n     * arrays allocated\n     */\n    private void nukeSymbols(boolean fill) {\n        _count = 0;\n        // reset spill-over to empty (starting at 7/8 of hash area)\n        _spilloverEnd = _spilloverStart();\n        // and long name area to empty, starting immediately after hash area\n        _longNameOffset = _hashSize << 3;\n        if (fill) {\n            Arrays.fill(_hashArea, 0);\n            Arrays.fill(_names, null);\n        }\n    }\n\n    /*\n    /**********************************************************\n    /* Helper methods\n    /**********************************************************\n     */\n\n    /**\n     * Helper method that calculates start of the spillover area\n     */\n    private final int _spilloverStart() {\n        // we'll need slot at 1.75x of hashSize, but with 4-ints per slot.\n        // So basically multiply by 7\n        int offset = _hashSize;\n        return (offset << 3) - offset;\n    }\n\n    protected void _reportTooManyCollisions()\n    {\n        // First: do not fuzz about small symbol tables; may get balanced by doubling up\n        if (_hashSize <= 1024) { // would have spill-over area of 128 entries\n            return;\n        }\n        throw new IllegalStateException(\"Spill-over slots in symbol table with \"+_count\n                +\" entries, hash area of \"+_hashSize+\" slots is now full (all \"\n                +(_hashSize >> 3)+\" slots -- suspect a DoS attack based on hash collisions.\"\n                +\" You can disable the check via `JsonFactory.Feature.FAIL_ON_SYMBOL_HASH_OVERFLOW`\");\n    }\n\n    static int _calcTertiaryShift(int primarySlots)\n    {\n        // first: we only get 1/4 of slots of primary, to divide\n        int tertSlots = (primarySlots) >> 2;\n        \n        // default is for buckets of 4 slots (each 4 ints, i.e. 1 << 4)\n        if (tertSlots < 64) {\n            return 4;\n        }\n        if (tertSlots <= 256) { // buckets of 8 slots (up to 256 == 32 x 8)\n            return 5;\n        }\n        if (tertSlots <= 1024) { // buckets of 16 slots (up to 1024 == 64 x 16)\n            return 6;\n        }\n        // and biggest buckets have 32 slots\n        return 7;\n    }\n\n    /*\n    /**********************************************************\n    /* Helper classes\n    /**********************************************************\n     */\n\n    /**\n     * Immutable value class used for sharing information as efficiently\n     * as possible, by only require synchronization of reference manipulation\n     * but not access to contents.\n     * \n     * @since 2.1\n     */\n    private final static class TableInfo\n    {\n        public final int size;\n        public final int count;\n        public final int tertiaryShift;\n        public final int[] mainHash;\n        public final String[] names;\n        public final int spilloverEnd;\n        public final int longNameOffset;\n\n        public TableInfo(int size, int count, int tertiaryShift, \n                int[] mainHash, String[] names, int spilloverEnd, int longNameOffset)\n        {\n            this.size = size;\n            this.count = count;\n            this.tertiaryShift = tertiaryShift;\n            this.mainHash = mainHash;\n            this.names = names;\n            this.spilloverEnd = spilloverEnd;\n            this.longNameOffset = longNameOffset;\n        }\n\n        public TableInfo(ByteQuadsCanonicalizer src)\n        {\n            size = src._hashSize;\n            count = src._count;\n            tertiaryShift = src._tertiaryShift;\n            mainHash = src._hashArea;\n            names = src._names;\n            spilloverEnd = src._spilloverEnd;\n            longNameOffset = src._longNameOffset;\n        }\n\n        public static TableInfo createInitial(int sz) {\n            int hashAreaSize = sz << 3;\n            int tertShift = _calcTertiaryShift(sz);\n\n            return new TableInfo(sz, // hashSize\n                    0, // count\n                    tertShift,\n                    new int[hashAreaSize], // mainHash, 2x slots, 4 ints per slot\n                    new String[sz << 1], // names == 2x slots\n                    hashAreaSize - sz, // at 7/8 of the total area\n                    hashAreaSize // longNameOffset, immediately after main hashes\n            );\n        }\n    }\n}"
    },
    {
        "id": 8,
        "filepath": "/mnt/disk1/cmd/defects4j_fixed/JacksonCore/JacksonCore_11_fixed/src/main/java/com/fasterxml/jackson/core/sym/ByteQuadsCanonicalizer.java",
        "precode": "            _hashArea = Arrays.copyOf(_hashArea, _hashArea.length);",
        "line": 877,
        "aftercode": "_hashArea = copyOf(_hashArea, _hashArea.length);"
    },
    {
        "id": 8,
        "filepath": "/mnt/disk1/cmd/defects4j_fixed/JacksonCore/JacksonCore_11_fixed/src/main/java/com/fasterxml/jackson/core/sym/ByteQuadsCanonicalizer.java",
        "precode": "            _hashShared = false;",
        "line": 879,
        "aftercode": "package com.fasterxml.jackson.core.sym;\n\nimport java.util.Arrays;\nimport java.util.concurrent.atomic.AtomicReference;\n\nimport com.fasterxml.jackson.core.JsonFactory;\nimport com.fasterxml.jackson.core.util.InternCache;\n\n/**\n * Replacement for <code>BytesToNameCanonicalizer</code> which aims at more localized\n * memory access due to flattening of name quad data.\n * Performance improvement modest for simple JSON document data binding (maybe 3%),\n * but should help more for larger symbol tables, or for binary formats like Smile.\n *\n * @since 2.6\n */\npublic final class ByteQuadsCanonicalizer\n{\n    /**\n     * Initial size of the primary hash area. Each entry consumes 4 ints (16 bytes),\n     * and secondary area is same as primary; so default size will use 2kB of memory_tertiaryStart\n     * (plus 64x4 or 64x8 (256/512 bytes) for references to Strings, and Strings\n     * themselves).\n     */\n    private static final int DEFAULT_T_SIZE = 64;\n//    private static final int DEFAULT_T_SIZE = 256;\n\n    /**\n     * Let's not expand symbol tables past some maximum size;\n     * this should protected against OOMEs caused by large documents\n     * with unique (~= random) names.\n     * Size is in \n     */\n    private static final int MAX_T_SIZE = 0x10000; // 64k entries == 2M mem hash area\n\n    /**\n     * No point in trying to construct tiny tables, just need to resize soon.\n     */\n    final static int MIN_HASH_SIZE = 16;\n    \n    /**\n     * Let's only share reasonably sized symbol tables. Max size set to 3/4 of 8k;\n     * this corresponds to 256k main hash index. This should allow for enough distinct\n     * names for almost any case, while preventing ballooning for cases where names\n     * are unique (or close thereof).\n     */\n    final static int MAX_ENTRIES_FOR_REUSE = 6000;\n\n    /*\n    /**********************************************************\n    /* Linkage, needed for merging symbol tables\n    /**********************************************************\n     */\n\n    /**\n     * Reference to the root symbol table, for child tables, so\n     * that they can merge table information back as necessary.\n     */\n    final protected ByteQuadsCanonicalizer _parent;\n\n    /**\n     * Member that is only used by the root table instance: root\n     * passes immutable state into child instances, and children\n     * may return new state if they add entries to the table.\n     * Child tables do NOT use the reference.\n     */\n    final protected AtomicReference<TableInfo> _tableInfo;\n    \n    /**\n     * Seed value we use as the base to make hash codes non-static between\n     * different runs, but still stable for lifetime of a single symbol table\n     * instance.\n     * This is done for security reasons, to avoid potential DoS attack via\n     * hash collisions.\n     */\n    final private int _seed;\n    \n    /*\n    /**********************************************************\n    /* Configuration\n    /**********************************************************\n     */\n\n    /**\n     * Whether canonical symbol Strings are to be intern()ed before added\n     * to the table or not.\n     *<p>\n     * NOTE: non-final to allow disabling intern()ing in case of excessive\n     * collisions.\n     */\n    protected boolean _intern;\n\n    /**\n     * Flag that indicates whether we should throw an exception if enough \n     * hash collisions are detected (true); or just worked around (false).\n     * \n     * @since 2.4\n     */\n    protected final boolean _failOnDoS;\n    \n    /*\n    /**********************************************************\n    /* First, main hash area info\n    /**********************************************************\n     */\n\n    /**\n     * Primary hash information area: consists of <code>2 * _hashSize</code>\n     * entries of 16 bytes (4 ints), arranged in a cascading lookup\n     * structure (details of which may be tweaked depending on expected rates\n     * of collisions).\n     */\n    protected int[] _hashArea;\n\n    /**\n     * Number of slots for primary entries within {@link #_hashArea}; which is\n     * at most <code>1/8</code> of actual size of the underlying array (4-int slots,\n     * primary covers only half of the area; plus, additional area for longer\n     * symbols after hash area).\n     */\n    protected int _hashSize;\n\n    /**\n     * Offset within {@link #_hashArea} where secondary entries start\n     */\n    protected int _secondaryStart;\n\n    /**\n     * Offset within {@link #_hashArea} where tertiary entries start\n     */\n    protected int _tertiaryStart;\n    \n    /**\n     * Constant that determines size of buckets for tertiary entries:\n     * <code>1 &lt;&lt; _tertiaryShift</code> is the size, and shift value\n     * is also used for translating from primary offset into\n     * tertiary bucket (shift right by <code>4 + _tertiaryShift</code>).\n     *<p>\n     * Default value is 2, for buckets of 4 slots; grows bigger with\n     * bigger table sizes.\n     */\n    protected int _tertiaryShift;\n\n    /**\n     * Total number of Strings in the symbol table; only used for child tables.\n     */\n    protected int _count;\n\n    /**\n     * Array that contains <code>String</code> instances matching\n     * entries in {@link #_hashArea}.\n     * Contains nulls for unused entries. Note that this size is twice\n     * that of {@link #_hashArea}\n     */\n    protected String[] _names;\n\n    /*\n    /**********************************************************\n    /* Then information on collisions etc\n    /**********************************************************\n     */\n\n    /**\n     * Pointer to the offset within spill-over area where there is room\n     * for more spilled over entries (if any).\n     * Spill over area is within fixed-size portion of {@link #_hashArea}.\n     */\n    protected int _spilloverEnd;\n\n    /**\n     * Offset within {@link #_hashArea} that follows main slots and contains\n     * quads for longer names (13 bytes or longers), and points to the\n     * first available int that may be used for appending quads of the next\n     * long name.\n     * Note that long name area follows immediately after the fixed-size\n     * main hash area ({@link #_hashArea}).\n     */\n    protected int _longNameOffset;\n\n    /**\n     * This flag is set if, after adding a new entry, it is deemed\n     * that a rehash is warranted if any more entries are to be added.\n     */\n    private transient boolean _needRehash;\n\n    /*\n    /**********************************************************\n    /* Sharing, versioning\n    /**********************************************************\n     */\n\n    // // // Which of the buffers may be shared (and are copy-on-write)?\n\n    /**\n     * Flag that indicates whether underlying data structures for\n     * the main hash area are shared or not. If they are, then they\n     * need to be handled in copy-on-write way, i.e. if they need\n     * to be modified, a copy needs to be made first; at this point\n     * it will not be shared any more, and can be modified.\n     *<p>\n     * This flag needs to be checked both when adding new main entries,\n     * and when adding new collision list queues (i.e. creating a new\n     * collision list head entry)\n     */\n    private boolean _hashShared;\n\n    /*\n    /**********************************************************\n    /* Life-cycle: constructors\n    /**********************************************************\n     */\n\n    /**\n     * Constructor used for creating per-<code>JsonFactory</code> \"root\"\n     * symbol tables: ones used for merging and sharing common symbols\n     * \n     * @param sz Initial primary hash area size\n     * @param intern Whether Strings contained should be {@link String#intern}ed\n     * @param seed Random seed valued used to make it more difficult to cause\n     *   collisions (used for collision-based DoS attacks).\n     */\n    private ByteQuadsCanonicalizer(int sz, boolean intern, int seed, boolean failOnDoS) {\n        _parent = null;\n        _seed = seed;\n        _intern = intern;\n        _failOnDoS = failOnDoS;\n        // Sanity check: let's now allow hash sizes below certain minimum value\n        if (sz < MIN_HASH_SIZE) {\n            sz = MIN_HASH_SIZE;\n        } else {\n            // Also; size must be 2^N; otherwise hash algorithm won't\n            // work... so let's just pad it up, if so\n            if ((sz & (sz - 1)) != 0) { // only true if it's 2^N\n                int curr = MIN_HASH_SIZE;\n                while (curr < sz) {\n                    curr += curr;\n                }\n                sz = curr;\n            }\n        }\n        _tableInfo = new AtomicReference<TableInfo>(TableInfo.createInitial(sz));\n    }\n\n    /**\n     * Constructor used when creating a child instance\n     */\n    private ByteQuadsCanonicalizer(ByteQuadsCanonicalizer parent, boolean intern,\n            int seed, boolean failOnDoS, TableInfo state)\n    {\n        _parent = parent;\n        _seed = seed;\n        _intern = intern;\n        _failOnDoS = failOnDoS;\n        _tableInfo = null; // not used by child tables\n\n        // Then copy shared state\n        _count = state.count;\n        _hashSize = state.size;\n        _secondaryStart = _hashSize << 2; // right after primary area\n        _tertiaryStart = _secondaryStart + (_secondaryStart >> 1); // right after secondary\n        _tertiaryShift = state.tertiaryShift;\n        \n        _hashArea = state.mainHash;\n        _names = state.names;\n\n        _spilloverEnd = state.spilloverEnd;\n        _longNameOffset = state.longNameOffset;\n\n        // and then set other state to reflect sharing status\n        _needRehash = false;\n        _hashShared = true;\n    }\n\n    /*\n    /**********************************************************\n    /* Life-cycle: factory methods, merging\n    /**********************************************************\n     */\n    \n    /**\n     * Factory method to call to create a symbol table instance with a\n     * randomized seed value.\n     */\n    public static ByteQuadsCanonicalizer createRoot() {\n        /* [Issue-21]: Need to use a variable seed, to thwart hash-collision\n         * based attacks.\n         */\n        long now = System.currentTimeMillis();\n        // ensure it's not 0; and might as well require to be odd so:\n        int seed = (((int) now) + ((int) (now >>> 32))) | 1;\n        return createRoot(seed);\n    }\n\n    /**\n     * Factory method that should only be called from unit tests, where seed\n     * value should remain the same.\n     */\n    protected static ByteQuadsCanonicalizer createRoot(int seed) {\n        return new ByteQuadsCanonicalizer(DEFAULT_T_SIZE, true, seed, true);\n    }\n    \n    /**\n     * Factory method used to create actual symbol table instance to\n     * use for parsing.\n     */\n    public ByteQuadsCanonicalizer makeChild(int flags) {\n        return new ByteQuadsCanonicalizer(this,\n                JsonFactory.Feature.INTERN_FIELD_NAMES.enabledIn(flags),\n                _seed,\n                JsonFactory.Feature.FAIL_ON_SYMBOL_HASH_OVERFLOW.enabledIn(flags),\n                _tableInfo.get());\n    }\n\n    /**\n     * Method called by the using code to indicate it is done\n     * with this instance. This lets instance merge accumulated\n     * changes into parent (if need be), safely and efficiently,\n     * and without calling code having to know about parent\n     * information\n     */\n    public void release()\n    {\n        // we will try to merge if child table has new entries\n        if (_parent != null && maybeDirty()) {\n            _parent.mergeChild(new TableInfo(this));\n            /* Let's also mark this instance as dirty, so that just in\n             * case release was too early, there's no corruption of possibly shared data.\n             */\n            _hashShared = true;\n        }\n    }\n\n    private void mergeChild(TableInfo childState)\n    {\n        final int childCount = childState.count;\n        TableInfo currState = _tableInfo.get();\n\n        // Should usually grow; but occasionally could also shrink if (but only if)\n        // collision list overflow ends up clearing some collision lists.\n        if (childCount == currState.count) {\n            return;\n        }\n\n        // One caveat: let's try to avoid problems with degenerate cases of documents with\n        // generated \"random\" names: for these, symbol tables would bloat indefinitely.\n        // One way to do this is to just purge tables if they grow\n        // too large, and that's what we'll do here.\n        if (childCount > MAX_ENTRIES_FOR_REUSE) {\n            // At any rate, need to clean up the tables\n            childState = TableInfo.createInitial(DEFAULT_T_SIZE);\n        }\n        _tableInfo.compareAndSet(currState, childState);\n    }\n\n    /*\n    /**********************************************************\n    /* API, accessors\n    /**********************************************************\n     */\n\n    public int size()\n    {\n        if (_tableInfo != null) { // root table\n            return _tableInfo.get().count;\n        }\n        // nope, child table\n        return _count;\n    }\n\n    /**\n     * Returns number of primary slots table has currently\n     */\n    public int bucketCount() { return _hashSize; }\n\n    /**\n     * Method called to check to quickly see if a child symbol table\n     * may have gotten additional entries. Used for checking to see\n     * if a child table should be merged into shared table.\n     */\n    public boolean maybeDirty() { return !_hashShared; }\n\n    public int hashSeed() { return _seed; }\n    \n    /**\n     * Method mostly needed by unit tests; calculates number of\n     * entries that are in the primary slot set. These are\n     * \"perfect\" entries, accessible with a single lookup\n     */\n    public int primaryCount()\n    {\n        int count = 0;\n        for (int offset = 3, end = _secondaryStart; offset < end; offset += 4) {\n            if (_hashArea[offset] != 0) {\n                ++count;\n            }\n        }\n        return count;\n    }\n\n    /**\n     * Method mostly needed by unit tests; calculates number of entries\n     * in secondary buckets\n     */\n    public int secondaryCount() {\n        int count = 0;\n        int offset = _secondaryStart + 3;\n        for (int end = _tertiaryStart; offset < end; offset += 4) {\n            if (_hashArea[offset] != 0) {\n                ++count;\n            }\n        }\n        return count;\n    }\n\n    /**\n     * Method mostly needed by unit tests; calculates number of entries\n     * in tertiary buckets\n     */\n    public int tertiaryCount() {\n        int count = 0;\n        int offset = _tertiaryStart + 3; // to 1.5x, starting point of tertiary\n        for (int end = offset + _hashSize; offset < end; offset += 4) {\n            if (_hashArea[offset] != 0) {\n                ++count;\n            }\n        }\n        return count;\n    }\n\n    /**\n     * Method mostly needed by unit tests; calculates number of entries\n     * in shared spillover area\n     */\n    public int spilloverCount() {\n        // difference between spillover end, start, divided by 4 (four ints per slot)\n        return (_spilloverEnd - _spilloverStart()) >> 2;\n    }\n\n    public int totalCount()\n    {\n        int count = 0;\n        for (int offset = 3, end = (_hashSize << 3); offset < end; offset += 4) {\n            if (_hashArea[offset] != 0) {\n                ++count;\n            }\n        }\n        return count;\n    }\n\n    @Override\n    public String toString() {\n        int pri = primaryCount();\n        int sec = secondaryCount();\n        int tert = tertiaryCount();\n        int spill = spilloverCount();\n        int total = totalCount();\n        return String.format(\"[%s: size=%d, hashSize=%d, %d/%d/%d/%d pri/sec/ter/spill (=%s), total:%d]\",\n                getClass().getName(), _count, _hashSize,\n                pri, sec, tert, spill, total, (pri+sec+tert+spill), total);\n    }\n\n    /*\n    /**********************************************************\n    /* Public API, accessing symbols\n    /**********************************************************\n     */\n\n    public String findName(int q1)\n    {\n        int offset = _calcOffset(calcHash(q1));\n        // first: primary match?\n        final int[] hashArea = _hashArea;\n\n        int len = hashArea[offset+3];\n\n        if (len == 1) {\n            if (hashArea[offset] == q1) {\n                return _names[offset >> 2];\n            }\n        } else if (len == 0) { // empty slot; unlikely but avoid further lookups if so\n            return null;\n        }\n        // secondary? single slot shared by N/2 primaries\n        int offset2 = _secondaryStart + ((offset >> 3) << 2);\n\n        len = hashArea[offset2+3];\n\n        if (len == 1) {\n            if (hashArea[offset2] == q1) {\n                return _names[offset2 >> 2];\n            }\n        } else if (len == 0) { // empty slot; unlikely but avoid further lookups if so\n            return null;\n        }\n\n        // tertiary lookup & spillovers best to offline\n        return _findSecondary(offset, q1);\n    }\n\n    public String findName(int q1, int q2)\n    {\n        int offset = _calcOffset(calcHash(q1, q2));\n\n        final int[] hashArea = _hashArea;\n\n        int len = hashArea[offset+3];\n\n        if (len == 2) {\n            if ((q1 == hashArea[offset]) && (q2 == hashArea[offset+1])) {\n                return _names[offset >> 2];\n            }\n        } else if (len == 0) { // empty slot; unlikely but avoid further lookups if so\n            return null;\n        }\n        // secondary?\n        int offset2 = _secondaryStart + ((offset >> 3) << 2);\n\n        len = hashArea[offset2+3];\n\n        if (len == 2) {\n            if ((q1 == hashArea[offset2]) && (q2 == hashArea[offset2+1])) {\n                return _names[offset2 >> 2];\n            }\n        } else if (len == 0) { // empty slot? Short-circuit if no more spillovers\n            return null;\n        }\n        return _findSecondary(offset, q1, q2);\n    }\n\n    public String findName(int q1, int q2, int q3)\n    {\n        int offset = _calcOffset(calcHash(q1, q2, q3));\n        final int[] hashArea = _hashArea;\n        int len = hashArea[offset+3];\n\n        if (len == 3) {\n            if ((q1 == hashArea[offset]) && (hashArea[offset+1] == q2) && (hashArea[offset+2] == q3)) {\n                return _names[offset >> 2];\n            }\n        } else if (len == 0) { // empty slot; unlikely but avoid further lookups if so\n            return null;\n        }\n        // secondary?\n        int offset2 = _secondaryStart + ((offset >> 3) << 2);\n\n        len = hashArea[offset2+3];\n\n        if (len == 3) {\n            if ((q1 == hashArea[offset2]) && (hashArea[offset2+1] == q2) && (hashArea[offset2+2] == q3)) {\n                return _names[offset2 >> 2];\n            }\n        } else if (len == 0) { // empty slot? Short-circuit if no more spillovers\n            return null;\n        }\n        return _findSecondary(offset, q1, q2, q3);\n    }\n\n    public String findName(int[] q, int qlen)\n    {\n        /* This version differs significantly, because longer names do not fit within cell.\n         * Rather, they contain hash in main slot, and offset+length to extension area\n         * that contains actual quads.\n         */\n        if (qlen < 4) { // another sanity check\n            if (qlen == 3) {\n                return findName(q[0], q[1], q[2]);\n            }\n            if (qlen == 2) {\n                return findName(q[0], q[1]);\n            }\n            return findName(q[0]);\n        }\n        final int hash = calcHash(q, qlen);\n        int offset = _calcOffset(hash);\n\n        final int[] hashArea = _hashArea;\n\n        final int len = hashArea[offset+3];\n        \n        if ((hash == hashArea[offset]) && (len == qlen)) {\n            // probable but not guaranteed: verify\n            if (_verifyLongName(q, qlen, hashArea[offset+1])) {\n                return _names[offset >> 2];\n            }\n        }\n        if (len == 0) { // empty slot; unlikely but avoid further lookups if so\n            return null;\n        }\n        // secondary?\n        int offset2 = _secondaryStart + ((offset >> 3) << 2);\n\n        final int len2 = hashArea[offset2+3];\n        if ((hash == hashArea[offset2]) && (len2 == qlen)) {\n            if (_verifyLongName(q, qlen, hashArea[offset2+1])) {\n                return _names[offset2 >> 2];\n            }\n        }\n        if (len == 0) { // empty slot? Short-circuit if no more spillovers\n            return null;\n        }\n        return _findSecondary(offset, hash, q, qlen);\n    }\n    \n    private final int _calcOffset(int hash)\n    {\n        // NOTE: simple for initial impl, but we may want to interleave it a bit\n        // in near future\n        // So: first, hash into primary hash index\n        int ix = hash & (_hashSize-1);\n        // keeping in mind we have 4 ints per entry\n        return (ix << 2);\n    }\n\n    /*\n    /**********************************************************\n    /* Access from spill-over areas\n    /**********************************************************\n     */\n\n    private String _findSecondary(int origOffset, int q1)\n    {\n        // tertiary area division is dynamic. First; its size is N/4 compared to\n        // primary hash size; and offsets are for 4 int slots. So to get to logical\n        // index would shift by 4. But! Tertiary area is further split into buckets,\n        // determined by shift value. And finally, from bucket back into physical offsets\n        int offset = _tertiaryStart + ((origOffset >> (_tertiaryShift + 2)) << _tertiaryShift);\n        final int[] hashArea = _hashArea;\n        final int bucketSize = (1 << _tertiaryShift);\n        for (int end = offset + bucketSize; offset < end; offset += 4) {\n            int len = hashArea[offset+3];\n            if ((q1 == hashArea[offset]) && (1 == len)) {\n                return _names[offset >> 2];\n            }\n            if (len == 0) {\n                return null;\n            }\n        }\n        // but if tertiary full, check out spill-over area as last resort\n        // shared spillover starts at 7/8 of the main hash area\n        // (which is sized at 2 * _hashSize), so:\n        for (offset = _spilloverStart(); offset < _spilloverEnd; offset += 4) {\n            if ((q1 == hashArea[offset]) && (1 == hashArea[offset+3])) {\n                return _names[offset >> 2];\n            }\n        }\n        return null;\n    }\n\n    private String _findSecondary(int origOffset, int q1, int q2)\n    {\n        int offset = _tertiaryStart + ((origOffset >> (_tertiaryShift + 2)) << _tertiaryShift);\n        final int[] hashArea = _hashArea;\n\n        final int bucketSize = (1 << _tertiaryShift);\n        for (int end = offset + bucketSize; offset < end; offset += 4) {\n            int len = hashArea[offset+3];\n            if ((q1 == hashArea[offset]) && (q2 == hashArea[offset+1]) && (2 == len)) {\n                return _names[offset >> 2];\n            }\n            if (len == 0) {\n                return null;\n            }\n        }\n        for (offset = _spilloverStart(); offset < _spilloverEnd; offset += 4) {\n            if ((q1 == hashArea[offset]) && (q2 == hashArea[offset+1]) && (2 == hashArea[offset+3])) {\n                return _names[offset >> 2];\n            }\n        }\n        return null;\n    }\n\n    private String _findSecondary(int origOffset, int q1, int q2, int q3)\n    {\n        int offset = _tertiaryStart + ((origOffset >> (_tertiaryShift + 2)) << _tertiaryShift);\n        final int[] hashArea = _hashArea;\n\n        final int bucketSize = (1 << _tertiaryShift);\n        for (int end = offset + bucketSize; offset < end; offset += 4) {\n            int len = hashArea[offset+3];\n            if ((q1 == hashArea[offset]) && (q2 == hashArea[offset+1]) && (q3 == hashArea[offset+2]) && (3 == len)) {\n                return _names[offset >> 2];\n            }\n            if (len == 0) {\n                return null;\n            }\n        }\n        for (offset = _spilloverStart(); offset < _spilloverEnd; offset += 4) {\n            if ((q1 == hashArea[offset]) && (q2 == hashArea[offset+1]) && (q3 == hashArea[offset+2])\n                    && (3 == hashArea[offset+3])) {\n                return _names[offset >> 2];\n            }\n        }\n        return null;\n    }\n\n    private String _findSecondary(int origOffset, int hash, int[] q, int qlen)\n    {\n        int offset = _tertiaryStart + ((origOffset >> (_tertiaryShift + 2)) << _tertiaryShift);\n        final int[] hashArea = _hashArea;\n\n        final int bucketSize = (1 << _tertiaryShift);\n        for (int end = offset + bucketSize; offset < end; offset += 4) {\n            int len = hashArea[offset+3];\n            if ((hash == hashArea[offset]) && (qlen == len)) {\n                if (_verifyLongName(q, qlen, hashArea[offset+1])) {\n                    return _names[offset >> 2];\n                }\n            }\n            if (len == 0) {\n                return null;\n            }\n        }\n        for (offset = _spilloverStart(); offset < _spilloverEnd; offset += 4) {\n            if ((hash == hashArea[offset]) && (qlen == hashArea[offset+3])) {\n                if (_verifyLongName(q, qlen, hashArea[offset+1])) {\n                    return _names[offset >> 2];\n                }\n            }\n        }\n        return null;\n    }\n    \n    private boolean _verifyLongName(int[] q, int qlen, int spillOffset)\n    {\n        final int[] hashArea = _hashArea;\n        // spillOffset assumed to be physical index right into quad string\n        int ix = 0;\n\n        switch (qlen) {\n        default:\n            return _verifyLongName2(q, qlen, spillOffset);\n        case 8:\n            if (q[ix++] != hashArea[spillOffset++]) return false;\n        case 7:\n            if (q[ix++] != hashArea[spillOffset++]) return false;\n        case 6:\n            if (q[ix++] != hashArea[spillOffset++]) return false;\n        case 5:\n            if (q[ix++] != hashArea[spillOffset++]) return false;\n        case 4: // always at least 4\n            if (q[ix++] != hashArea[spillOffset++]) return false;\n            if (q[ix++] != hashArea[spillOffset++]) return false;\n            if (q[ix++] != hashArea[spillOffset++]) return false;\n            if (q[ix++] != hashArea[spillOffset++]) return false;\n        }\n        return true;\n    }\n\n    private boolean _verifyLongName2(int[] q, int qlen, int spillOffset)\n    {\n        int ix = 0;\n        do {\n            if (q[ix++] != _hashArea[spillOffset++]) {\n                return false;\n            }\n        } while (ix < qlen);\n        return true;\n    }\n\n    /*\n    /**********************************************************\n    /* API, mutators\n    /**********************************************************\n     */\n\n    public String addName(String name, int q1) {\n        _verifySharing();\n        if (_intern) {\n            name = InternCache.instance.intern(name);\n        }\n        int offset = _findOffsetForAdd(calcHash(q1));\n        _hashArea[offset] = q1;\n        _hashArea[offset+3] = 1;\n        _names[offset >> 2] = name;\n        ++_count;\n        _verifyNeedForRehash();\n        return name;\n    }\n\n    public String addName(String name, int q1, int q2) {\n        _verifySharing();\n        if (_intern) {\n            name = InternCache.instance.intern(name);\n        }\n        int hash = (q2 == 0) ? calcHash(q1) : calcHash(q1, q2);\n        int offset = _findOffsetForAdd(hash);\n        _hashArea[offset] = q1;\n        _hashArea[offset+1] = q2;\n        _hashArea[offset+3] = 2;\n        _names[offset >> 2] = name;\n        ++_count;\n        _verifyNeedForRehash();\n        return name;\n    }\n\n    public String addName(String name, int q1, int q2, int q3) {\n        _verifySharing();\n        if (_intern) {\n            name = InternCache.instance.intern(name);\n        }\n        int offset = _findOffsetForAdd(calcHash(q1, q2, q3));\n        _hashArea[offset] = q1;\n        _hashArea[offset+1] = q2;\n        _hashArea[offset+2] = q3;\n        _hashArea[offset+3] = 3;\n        _names[offset >> 2] = name;\n        ++_count;\n        _verifyNeedForRehash();\n        return name;\n    }\n\n    public String addName(String name, int[] q, int qlen)\n    {\n        _verifySharing();\n        if (_intern) {\n            name = InternCache.instance.intern(name);\n        }\n        int offset;\n        \n        switch (qlen) {\n        case 1:\n        {\n                offset = _findOffsetForAdd(calcHash(q[0]));\n                _hashArea[offset] = q[0];\n                _hashArea[offset+3] = 1;\n            }\n            break;\n        case 2:\n            {\n                offset = _findOffsetForAdd(calcHash(q[0], q[1]));\n                _hashArea[offset] = q[0];\n                _hashArea[offset+1] = q[1];\n                _hashArea[offset+3] = 2;\n            }\n            break;\n        case 3:\n            {\n                offset = _findOffsetForAdd(calcHash(q[0], q[1], q[2]));\n                _hashArea[offset] = q[0];\n                _hashArea[offset+1] = q[1];\n                _hashArea[offset+2] = q[2];\n                _hashArea[offset+3] = 3;\n            }\n            break;\n        default:\n            final int hash = calcHash(q, qlen);\n            offset = _findOffsetForAdd(hash);\n\n            _hashArea[offset] = hash;\n            int longStart = _appendLongName(q, qlen);\n            _hashArea[offset+1] = longStart;\n            _hashArea[offset+3] = qlen;\n        }\n        // plus add the actual String\n        _names[offset >> 2] = name;\n\n        // and finally; see if we really should rehash.\n        ++_count;\n        _verifyNeedForRehash();\n        return name;\n    }\n\n    private void _verifyNeedForRehash() {\n        // Yes if above 80%, or above 50% AND have ~1% spill-overs\n        if (_count > (_hashSize >> 1)) { // over 50%\n            int spillCount = (_spilloverEnd - _spilloverStart()) >> 2;\n            if ((spillCount > (1 + _count >> 7))\n                    || (_count > (_hashSize * 0.80))) {\n                _needRehash = true;\n            }\n        }\n    }\n\n    private void _verifySharing()\n    {\n        if (_hashShared) {\n            _hashArea = Arrays.copyOf(_hashArea, _hashArea.length);\n            _names = Arrays.copyOf(_names, _names.length);\n_verifyNeedForRehash();\n            _hashShared = false;            // 09-Sep-2015, tatu: As per [jackson-core#216], also need to ensure\n            //    we rehash as needed, as need-rehash flag is not copied from parent\n            _verifyNeedForRehash();\n}\n        }\n        if (_needRehash) {\n            rehash();\n        }\n    }\n\n    /**\n     * Method called to find the location within hash table to add a new symbol in.\n     */\n    private int _findOffsetForAdd(int hash)\n    {\n        // first, check the primary:\n        int offset = _calcOffset(hash);\n        final int[] hashArea = _hashArea;\n        if (hashArea[offset+3] == 0) {\n//System.err.printf(\" PRImary slot #%d, hash %X\\n\", (offset>>2), hash & 0x7F);\n            return offset;\n        }\n        // then secondary\n        int offset2 = _secondaryStart + ((offset >> 3) << 2);\n        if (hashArea[offset2+3] == 0) {\n//System.err.printf(\" SECondary slot #%d (start x%X), hash %X\\n\",(offset >> 3), _secondaryStart, (hash & 0x7F));\n            return offset2;\n        }\n        // if not, tertiary?\n\n        offset2 = _tertiaryStart + ((offset >> (_tertiaryShift + 2)) << _tertiaryShift);\n        final int bucketSize = (1 << _tertiaryShift);\n        for (int end = offset2 + bucketSize; offset2 < end; offset2 += 4) {\n            if (hashArea[offset2+3] == 0) {\n//System.err.printf(\" TERtiary slot x%X (from x%X, start x%X), hash %X.\\n\", offset2, ((offset >> (_tertiaryShift + 2)) << _tertiaryShift), _tertiaryStart, (hash & 0x7F));\n                return offset2;\n            }\n        }\n\n        // and if even tertiary full, append at the end of spill area\n        offset = _spilloverEnd;\n        _spilloverEnd += 4;\n\n//System.err.printf(\" SPIll-over at x%X; start x%X; end x%X, hash %X\\n\", offset, _spilloverStart(), _hashArea.length, (hash & 0x7F));\n        \n        // one caveat: in the unlikely event if spill-over filling up,\n        // check if that could be considered a DoS attack; handle appropriately\n        // (NOTE: approximate for now; we could verify details if that becomes necessary)\n        /* 31-Jul-2015, tatu: Note that spillover area does NOT end at end of array,\n         *   since \"long names\" area follows. Instead, need to calculate from hash size.\n         */\n        final int end = (_hashSize << 3);\n        if (_spilloverEnd >= end) {\n            if (_failOnDoS) {\n                _reportTooManyCollisions();\n            }\n            // and if we didn't fail, we'll simply force rehash for next add\n            // (which, in turn, may double up or nuke contents, depending on size etc)\n            _needRehash = true;\n        }\n        return offset;\n    }\n\n    private int _appendLongName(int[] quads, int qlen)\n    {\n        int start = _longNameOffset;\n        \n        // note: at this point we must already be shared. But may not have enough space\n        if ((start + qlen) > _hashArea.length) {\n            // try to increment in reasonable chunks; at least space that we need\n            int toAdd = (start + qlen) - _hashArea.length;\n            // but at least 1/8 of regular hash area size or 16kB (whichever smaller)\n            int minAdd = Math.min(4096, _hashSize);\n\n            int newSize = _hashArea.length + Math.max(toAdd, minAdd);\n            _hashArea = Arrays.copyOf(_hashArea, newSize);\n        }\n        System.arraycopy(quads, 0, _hashArea, start, qlen);\n        _longNameOffset += qlen;\n        return start;\n    }\n\n    /*\n    /**********************************************************\n    /* Hash calculation\n    /**********************************************************\n     */\n\n    /* Note on hash calculation: we try to make it more difficult to\n     * generate collisions automatically; part of this is to avoid\n     * simple \"multiply-add\" algorithm (like JDK String.hashCode()),\n     * and add bit of shifting. And other part is to make this\n     * non-linear, at least for shorter symbols.\n     */\n    \n    // JDK uses 31; other fine choices are 33 and 65599, let's use 33\n    // as it seems to give fewest collisions for us\n    // (see [http://www.cse.yorku.ca/~oz/hash.html] for details)\n    private final static int MULT = 33;\n    private final static int MULT2 = 65599;\n    private final static int MULT3 = 31;\n    \n    public int calcHash(int q1)\n    {\n        int hash = q1 ^ _seed;\n        /* 29-Mar-2015, tatu: Earlier used 15 + 9 right shifts, which worked ok\n         *    except for one specific problem case: numbers. So needed to make sure\n         *    that all 4 least-significant bits participate in hash. Couple of ways\n         *    to work it out, but this is the simplest, fast and seems to do ok.\n         */\n        hash += (hash >>> 16); // to xor hi- and low- 16-bits\n        hash ^= (hash << 3); // shuffle back a bit\n        hash += (hash >>> 12); // and bit more\n        return hash;\n    }\n\n    public int calcHash(int q1, int q2)\n    {\n        // For two quads, let's change algorithm a bit, to spice\n        // things up (can do bit more processing anyway)\n        int hash = q1;\n\n        hash += (hash >>> 15); // try mixing first and second byte pairs first\n        hash ^= (hash >>> 9); // as well as lowest 2 bytes\n        hash += (q2 * MULT); // then add second quad\n        hash ^= _seed;\n        hash += (hash >>> 16); // and shuffle some more\n        hash ^= (hash >>> 4);\n        hash += (hash << 3);\n        \n        return hash;\n    }\n\n    public int calcHash(int q1, int q2, int q3)\n    { // use same algorithm as multi-byte, tested to work well\n        int hash = q1 ^ _seed;\n        hash += (hash >>> 9);\n        hash *= MULT3;\n        hash += q2;\n        hash *= MULT;\n        hash += (hash >>> 15);\n        hash ^= q3;\n        // 26-Mar-2015, tatu: As per two-quad case, a short shift seems to help more here\n        hash += (hash >>> 4);\n\n        hash += (hash >>> 15);\n        hash ^= (hash << 9);\n\n        return hash;\n    }\n\n    public int calcHash(int[] q, int qlen)\n    {\n        if (qlen < 4) {\n            throw new IllegalArgumentException();\n        }\n        /* And then change handling again for \"multi-quad\" case; mostly\n         * to make calculation of collisions less fun. For example,\n         * add seed bit later in the game, and switch plus/xor around,\n         * use different shift lengths.\n         */\n        int hash = q[0] ^ _seed;\n        hash += (hash >>> 9);\n        hash += q[1];\n        hash += (hash >>> 15);\n        hash *= MULT;\n        hash ^= q[2];\n        hash += (hash >>> 4);\n\n        for (int i = 3; i < qlen; ++i) {\n            int next = q[i];\n            next = next ^ (next >> 21);\n            hash += next;\n        }\n        hash *= MULT2;\n        \n        // and finally shuffle some more once done\n        hash += (hash >>> 19);\n        hash ^= (hash << 5);\n        return hash;\n    }\n\n    /*\n    /**********************************************************\n    /* Rehashing\n    /**********************************************************\n     */\n\n    private void rehash()\n    {\n        _needRehash = false;\n        // Note: since we'll make copies, no need to unshare, can just mark as such:\n        _hashShared = false;\n\n        // And then we can first deal with the main hash area. Since we are expanding\n        // linearly (double up), we know there'll be no collisions during this phase.\n        final int[] oldHashArea = _hashArea;\n        final String[] oldNames = _names;\n        final int oldSize = _hashSize;\n        final int oldCount = _count;\n        final int newSize = oldSize + oldSize;\n        final int oldEnd = _spilloverEnd;\n\n        /* 13-Mar-2010, tatu: Let's guard against OOME that could be caused by\n         *    large documents with unique (or mostly so) names\n         */\n        if (newSize > MAX_T_SIZE) {\n            nukeSymbols(true);\n            return;\n        }\n        // double up main hash area, but do not expand long-name area:\n        _hashArea = new int[oldHashArea.length + (oldSize<<3)];\n        _hashSize = newSize;\n        _secondaryStart = (newSize << 2); // 4 ints per entry\n        _tertiaryStart = _secondaryStart + (_secondaryStart >> 1); // right after secondary\n        _tertiaryShift = _calcTertiaryShift(newSize);\n        \n        // and simply double up name array\n        _names = new String[oldNames.length << 1];\n        nukeSymbols(false);\n\n        // Plus we can scan only through the primary hash area, looking for non-empty\n        // slots, without worrying about ordering. This should never reduce priority\n        // of existing entries: primaries remain primaries; however, due to increased\n        // space, secondaries may become primaries etc\n\n        int copyCount = 0;\n        int[] q = new int[16];\n        for (int offset = 0, end = oldEnd; offset < end; offset += 4) {\n            int len = oldHashArea[offset+3];\n            if (len == 0) { // empty slot, skip\n                continue;\n            }\n            ++copyCount;\n            String name = oldNames[offset>>2];\n            switch (len) {\n            case 1:\n                q[0] = oldHashArea[offset];\n                addName(name, q, 1);\n                break;\n            case 2:\n                q[0] = oldHashArea[offset];\n                q[1] = oldHashArea[offset+1];\n                addName(name, q, 2);\n                break;\n            case 3:\n                q[0] = oldHashArea[offset];\n                q[1] = oldHashArea[offset+1];\n                q[2] = oldHashArea[offset+2];\n                addName(name, q, 3);\n                break;\n            default:\n                if (len > q.length) {\n                    q = new int[len];\n                }\n                // #0 is hash, #1 offset\n                int qoff = oldHashArea[offset+1];\n                System.arraycopy(oldHashArea, qoff, q, 0, len);\n                addName(name, q, len);\n                break;\n            }\n        }\n\n        // Sanity checks: since corruption difficult to detect, assert explicitly\n        // with production code\n        if (copyCount != oldCount) {\n            throw new IllegalStateException(\"Failed rehash(): old count=\"+oldCount+\", copyCount=\"+copyCount);\n        }\n    }\n\n    /**\n     * Helper method called to empty all shared symbols, but to leave\n     * arrays allocated\n     */\n    private void nukeSymbols(boolean fill) {\n        _count = 0;\n        // reset spill-over to empty (starting at 7/8 of hash area)\n        _spilloverEnd = _spilloverStart();\n        // and long name area to empty, starting immediately after hash area\n        _longNameOffset = _hashSize << 3;\n        if (fill) {\n            Arrays.fill(_hashArea, 0);\n            Arrays.fill(_names, null);\n        }\n    }\n\n    /*\n    /**********************************************************\n    /* Helper methods\n    /**********************************************************\n     */\n\n    /**\n     * Helper method that calculates start of the spillover area\n     */\n    private final int _spilloverStart() {\n        // we'll need slot at 1.75x of hashSize, but with 4-ints per slot.\n        // So basically multiply by 7\n        int offset = _hashSize;\n        return (offset << 3) - offset;\n    }\n\n    protected void _reportTooManyCollisions()\n    {\n        // First: do not fuzz about small symbol tables; may get balanced by doubling up\n        if (_hashSize <= 1024) { // would have spill-over area of 128 entries\n            return;\n        }\n        throw new IllegalStateException(\"Spill-over slots in symbol table with \"+_count\n                +\" entries, hash area of \"+_hashSize+\" slots is now full (all \"\n                +(_hashSize >> 3)+\" slots -- suspect a DoS attack based on hash collisions.\"\n                +\" You can disable the check via `JsonFactory.Feature.FAIL_ON_SYMBOL_HASH_OVERFLOW`\");\n    }\n\n    static int _calcTertiaryShift(int primarySlots)\n    {\n        // first: we only get 1/4 of slots of primary, to divide\n        int tertSlots = (primarySlots) >> 2;\n        \n        // default is for buckets of 4 slots (each 4 ints, i.e. 1 << 4)\n        if (tertSlots < 64) {\n            return 4;\n        }\n        if (tertSlots <= 256) { // buckets of 8 slots (up to 256 == 32 x 8)\n            return 5;\n        }\n        if (tertSlots <= 1024) { // buckets of 16 slots (up to 1024 == 64 x 16)\n            return 6;\n        }\n        // and biggest buckets have 32 slots\n        return 7;\n    }\n\n    /*\n    /**********************************************************\n    /* Helper classes\n    /**********************************************************\n     */\n\n    /**\n     * Immutable value class used for sharing information as efficiently\n     * as possible, by only require synchronization of reference manipulation\n     * but not access to contents.\n     * \n     * @since 2.1\n     */\n    private final static class TableInfo\n    {\n        public final int size;\n        public final int count;\n        public final int tertiaryShift;\n        public final int[] mainHash;\n        public final String[] names;\n        public final int spilloverEnd;\n        public final int longNameOffset;\n\n        public TableInfo(int size, int count, int tertiaryShift, \n                int[] mainHash, String[] names, int spilloverEnd, int longNameOffset)\n        {\n            this.size = size;\n            this.count = count;\n            this.tertiaryShift = tertiaryShift;\n            this.mainHash = mainHash;\n            this.names = names;\n            this.spilloverEnd = spilloverEnd;\n            this.longNameOffset = longNameOffset;\n        }\n\n        public TableInfo(ByteQuadsCanonicalizer src)\n        {\n            size = src._hashSize;\n            count = src._count;\n            tertiaryShift = src._tertiaryShift;\n            mainHash = src._hashArea;\n            names = src._names;\n            spilloverEnd = src._spilloverEnd;\n            longNameOffset = src._longNameOffset;\n        }\n\n        public static TableInfo createInitial(int sz) {\n            int hashAreaSize = sz << 3;\n            int tertShift = _calcTertiaryShift(sz);\n\n            return new TableInfo(sz, // hashSize\n                    0, // count\n                    tertShift,\n                    new int[hashAreaSize], // mainHash, 2x slots, 4 ints per slot\n                    new String[sz << 1], // names == 2x slots\n                    hashAreaSize - sz, // at 7/8 of the total area\n                    hashAreaSize // longNameOffset, immediately after main hashes\n            );\n        }\n    }\n}"
    }
]